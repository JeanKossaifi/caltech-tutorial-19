{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the size of your minibatch\n",
    "batch_size = 32\n",
    "\n",
    "device = 'cpu'\n",
    "# to run on GPU, uncomment the following line:\n",
    "#device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a deep convolutional neural network on the MNIST dataset. It consists of 70,000 images (60,000 for training and 10,000 for testing) of hand written digits. Our task is to predict the digit represented by each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data \n",
    "\n",
    "Note the normalisation (remove the mean, divide by the std)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('~/datasets/', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('~/datasets/', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's visualise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a batch of images and the corresponding labels (the class each sample belongs to).\n",
    "batch has (batch_size, n_channels, height, width) and labels is simply of shape (batch_size, ).\n",
    "Since the samples of MNIST are black and white images, n_channels is 1, let's remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.squeeze()  # By default, removes the dimensions of size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToTensor() converts the images from uint8 (values from 0 to 255) to float32 (ranging from 0 to 1). We typically would need to convert them back to uint8 images to properly visualise them. However, in this case, since they are just grayscale images, we don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_columns = 5\n",
    "n_rows = 5\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "index = 0\n",
    "for row in range(n_rows):\n",
    "    for column in range(n_columns):\n",
    "        ax = fig.add_subplot(n_rows, n_columns, index+1)\n",
    "        ax.imshow(batch[index].detach().cpu().numpy(), cmap=plt.cm.Greys_r)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(labels[index].item())\n",
    "        index += 1\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 0.8, left = 0, \n",
    "        hspace = 0, wspace = 0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the net\n",
    "\n",
    "Our network will be composed of a series of two convolutions, pooling, non-linearity, followed by a flattening and fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10) # We output log-probabilities for 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the input is (bs, 1, 28, 28)\n",
    "        x = self.conv1(x) # Loose 2 pixels on each side\n",
    "        \n",
    "        # x is now (bs, 10, 24, 24)\n",
    "        x = F.max_pool2d(x, 2) # divide resolution  by two\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        # x is (bs, 20, 8, 8)\n",
    "        \n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # x is (bs, 20, 4, 4)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(-1, 320) \n",
    "        # we flattened x (320 = 20*4*4)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x is (bs, 50)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        # x is (bs, 10)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 5 # Number of epochs\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Send the data and label to the correct device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Important: do not forget to reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Pass the data through the networks\n",
    "        output = model(data)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backprogragate the gradient\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # That's just printing some info...\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss = criterion(output,target)\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('mean: {}'.format(test_loss))\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "       100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see how our model did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, true_labels = next(iter(test_loader))\n",
    "data, target = images.to(device), true_labels.to(device)\n",
    "output = model(images)\n",
    "predicted_label = output.data.max(1, keepdim=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_columns = 5\n",
    "n_rows = 5\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "index = 0\n",
    "for row in range(n_rows):\n",
    "    for column in range(n_columns):\n",
    "        ax = fig.add_subplot(n_rows, n_columns, index+1)\n",
    "        ax.imshow(images[index].detach().cpu().numpy()[0], cmap=plt.cm.Greys_r)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(predicted_label[index].item())\n",
    "        index += 1\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 0.8, left = 0, \n",
    "        hspace = 0, wspace = 0)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
